{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec216685-5ec3-497c-9ef8-e1758ca30423",
   "metadata": {},
   "source": [
    "# LLM Strict JSON Framework\n",
    "- Created by John Tan Chong Min\n",
    "- 3 Jul 2023\n",
    "- Collaborators welcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be2280c7-1d2c-4639-b4be-032313ec1b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "import re\n",
    "\n",
    "#API Keys\n",
    "os.environ['OPENAI_API_TOKEN'] = 'YOUR_API_KEY_HERE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aed3bc4-8c94-4fda-aeff-08bf6d75723e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Normal GPT Chat Function\n",
    "\n",
    "- Normal way to invoke OpenAI API for GPT Models\n",
    "- Can be very verbose in its replies\n",
    "- Not well structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06f30da2-eaa6-4f9d-9eea-2e766883a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(system_prompt, user_prompt, model = 'gpt-3.5-turbo', temperature = 0, verbose = False):\n",
    "    ''' Normal call of OpenAI API '''\n",
    "    response = openai.ChatCompletion.create(\n",
    "    temperature = temperature,\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ])\n",
    "    \n",
    "    res = response['choices'][0]['message']['content']\n",
    "    \n",
    "    if verbose:\n",
    "        print('System prompt:', system_prompt)\n",
    "        print('User prompt:', user_prompt)\n",
    "        print('GPT response:', res)\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "505258eb-7739-4829-9335-b1fdcbbf2a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number 5 is an odd number.\n"
     ]
    }
   ],
   "source": [
    "res = chat(system_prompt = \"You are a friendly assistant\", \n",
    "     user_prompt = \"Is the number 5 even or odd?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77477080-892f-42de-9acd-7e440fd50de0",
   "metadata": {},
   "source": [
    "# Strict Output Formatting\n",
    "- Use when you want to force the function output to be a json format\n",
    "- Helps a lot with minimizing unnecessary explanations of ChatGPT, and ensuring all output fields are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78815bbd-f602-45c0-bb63-bd4ee5cc5fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strict_output(system_prompt, user_prompt, output_format, default_category = \"\", output_value_only = False,\n",
    "                  model = 'gpt-3.5-turbo', temperature = 0, num_tries = 2, verbose = False):\n",
    "    ''' Ensures that OpenAI will always adhere to the desired output json format. \n",
    "    Uses rule-based iterative feedback to ask GPT to self-correct.\n",
    "    Keeps trying up to num_tries it it does not. Returns empty json if unable to after num_tries iterations.\n",
    "    If output field is a list, will treat as a classification problem and output best classification category.\n",
    "    Text enclosed within < > will generated by GPT accordingly'''\n",
    "\n",
    "    # if the user input is in a list, we also process the output as a list of json\n",
    "    list_input = isinstance(user_prompt, list)\n",
    "    # if the output format contains dynamic elements of < or >, then add to the prompt to handle dynamic elements\n",
    "    dynamic_elements = '<' in str(output_format)\n",
    "    # if the output format contains list elements of [ or ], then we add to the prompt to handle lists\n",
    "    list_output = '[' in str(output_format)\n",
    "    \n",
    "    # start off with no error message\n",
    "    error_msg = ''\n",
    "    \n",
    "    for i in range(num_tries):\n",
    "        \n",
    "        output_format_prompt = f'''\\nYou are to output the following in json format: {output_format}. \n",
    "Do not put quotation marks or escape character \\ in the output fields.'''\n",
    "        \n",
    "        if list_output:\n",
    "            output_format_prompt += f'''\\nIf output field is a list, classify output into the best element of the list.'''\n",
    "        \n",
    "        # if output_format contains dynamic elements, process it accordingly\n",
    "        if dynamic_elements: \n",
    "            output_format_prompt += f'''\n",
    "Any text enclosed by < and > indicates you must generate content to replace it. Example input: Go to <location>, Example output: Go to the garden\n",
    "Any output key containing < and > indicates you must generate the key name to replace it. Example input: {{'<location>': 'description of location'}}, Example output: {{school: a place for education}}'''\n",
    "\n",
    "        # if input is in a list format, ask it to generate json in a list\n",
    "        if list_input:\n",
    "            output_format_prompt += '''\\nGenerate a list of json, one json for each input element.'''\n",
    "            \n",
    "        # Use OpenAI to get a response\n",
    "        response = openai.ChatCompletion.create(\n",
    "          temperature = temperature,\n",
    "          model=model,\n",
    "          messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt + output_format_prompt + error_msg},\n",
    "            {\"role\": \"user\", \"content\": str(user_prompt)}\n",
    "          ]\n",
    "        )\n",
    "\n",
    "        res = response['choices'][0]['message']['content'].replace('\\'', '\"')\n",
    "        \n",
    "        # ensure that we don't replace away aprostophes in text \n",
    "        res = re.sub(r\"(\\w)\\\"(\\w)\", r\"\\1'\\2\", res)\n",
    "\n",
    "        if verbose:\n",
    "            print('System prompt:', system_prompt + output_format_prompt + error_msg)\n",
    "            print('\\nUser prompt:', str(user_prompt))\n",
    "            print('\\nGPT response:', res)\n",
    "        \n",
    "        # try-catch block to ensure output format is adhered to\n",
    "        try:\n",
    "            output = json.loads(res)\n",
    "            if isinstance(user_prompt, list):\n",
    "                if not isinstance(output, list): raise Exception(\"Output format not in a list of json\")\n",
    "            else:\n",
    "                output = [output]\n",
    "                \n",
    "            # check for each element in the output_list, the format is correctly adhered to\n",
    "            for index in range(len(output)):\n",
    "                for key in output_format.keys():\n",
    "                    # unable to ensure accuracy of dynamic output header, so skip it\n",
    "                    if '<' in key or '>' in key: continue\n",
    "                    # if output field missing, raise an error\n",
    "                    if key not in output[index]: raise Exception(f\"{key} not in json output\")\n",
    "                    # check that one of the choices given for the list of words is an unknown\n",
    "                    if isinstance(output_format[key], list):\n",
    "                        choices = output_format[key]\n",
    "                        # ensure output is not a list\n",
    "                        if isinstance(output[index][key], list):\n",
    "                            output[index][key] = output[index][key][0]\n",
    "                        # output the default category (if any) if GPT is unable to identify the category\n",
    "                        if output[index][key] not in choices and default_category:\n",
    "                            output[index][key] = default_category\n",
    "                        # if the output is a description format, get only the label\n",
    "                        if ':' in output[index][key]:\n",
    "                            output[index][key] = output[index][key].split(':')[0]\n",
    "                            \n",
    "                # if we just want the values for the outputs\n",
    "                if output_value_only:\n",
    "                    output[index] = [value for value in output[index].values()]\n",
    "                    # just output without the list if there is only one element\n",
    "                    if len(output[index]) == 1:\n",
    "                        output[index] = output[index][0]\n",
    "                    \n",
    "            return output if list_input else output[0]\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"\\n\\nResult: {res}\\n\\nError message: {str(e)}\"\n",
    "            print(\"An exception occurred:\", str(e))\n",
    "            print(\"Current invalid json format:\", res)\n",
    "         \n",
    "    return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56773e55-2cce-4ba4-b6a3-8377bc8f8397",
   "metadata": {},
   "source": [
    "## Overall Open-ended generation\n",
    "- **system_prompt**: Write in whatever you want GPT to become. \"You are a \\<purpose in life\\>\"\n",
    "- **user_prompt**: The user input. Later, when we use it as a function, this is the function input\n",
    "- **output_format**: JSON format with the key as the output key, and the value as the output description\n",
    "    - The output keys will be preserved exactly, while GPT will generate content to match the description of the value as best as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e93a96b1-dba4-438a-bd29-1e02b9f65052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = '''\n",
    "One, two, three, four, five,\n",
    "Once I caught a fish alive,\n",
    "Six, seven, eight, nine, ten,\n",
    "Then I let it go again.\n",
    "Why did you let it go?\n",
    "Because it bit my finger so.\n",
    "Which finger did it bite?\n",
    "This little finger on my right'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "671544b2-c16e-4fe8-b775-76a3a2c8db90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Summary': 'Once caught fish alive, let go, bit finger', 'Entity Caught': 'fish', 'Finger Bitten': 'little finger', 'Numbers': ['One', 'two', 'three', 'four', 'five', 'Six', 'seven', 'eight', 'nine', 'ten']}\n"
     ]
    }
   ],
   "source": [
    "# Open-ended information extraction from text\n",
    "res = strict_output(system_prompt = 'You are a friendly assistant meant to extract information from text', \n",
    "                    user_prompt = text,\n",
    "                    output_format = {\"Summary\": \"Summarize the text in 10 words\", \"Entity Caught\": \"name of entity caught\", \n",
    "                                 \"Finger Bitten\": \"finger which was bitten\", \"Numbers\": \"List of numbers\"})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5b3558-5a4a-4bce-a86f-6f218075d899",
   "metadata": {},
   "source": [
    "## List-based constraining of outputs\n",
    "\n",
    "- You can constrain the output of a field by using a list of categories. Then GPT will treat it as a classification problem and return one of the categories\n",
    "    - Example input text: \"I am so elated!\"\n",
    "    - Example output_format: {\"Sentiment\": [\"happy\", \"sad\", \"neutral\"]}\n",
    "    - Example output: {\"Sentiment\": \"happy\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f192d75-6710-48fc-8e6d-6828a6f4bdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sentiment': 'happy'}\n"
     ]
    }
   ],
   "source": [
    "res = strict_output(system_prompt = 'You are a friendly assistant meant to extract information from text', \n",
    "                    user_prompt = \"I am so elated\",\n",
    "                    output_format = {\"Sentiment\": [\"happy\", \"sad\", \"neutral\"]})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9de5e323-43de-417a-98b2-34b0f1d7ba95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Summary': 'Once caught fish alive, let go, bit finger right', 'Entity Caught': 'living', 'Finger Bitten': 'right', 'Numbers': ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten']}\n"
     ]
    }
   ],
   "source": [
    "# We want to constrain some input to within a fixed list\n",
    "# If the right classification cannot be found in the list, GPT will output its proposed category name\n",
    "res = strict_output(system_prompt = 'You are a friendly assistant meant to extract information from text', \n",
    "                    user_prompt = text,\n",
    "                    output_format = {\"Summary\": \"Summarize the text in 10 words\", \"Entity Caught\": [\"living\", \"non-living\"], \n",
    "                                 \"Finger Bitten\": [\"left\", \"middle\"], \"Numbers\": \"List of numbers\"})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d95223a0-26ef-48c8-b56d-f4ed1dcd0cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Summary': 'Once caught fish alive, let go, bit finger right', 'Entity Caught': 'living', 'Finger Bitten': 'Unable to Classify', 'Numbers': ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten']}\n"
     ]
    }
   ],
   "source": [
    "# We want to constrain some input to within a fixed list\n",
    "# If you want to GPT to flag out when a classification is not found in the list, assign some text to default_category\n",
    "res = strict_output(system_prompt = 'You are a friendly assistant meant to extract information from text', \n",
    "            user_prompt = text,\n",
    "            output_format = {\"Summary\": \"Summarize the text in 10 words\", \"Entity Caught\": [\"living\", \"non-living\"], \n",
    "                                 \"Finger Bitten\": [\"left\", \"middle\"], \"Numbers\": \"List of numbers\"},\n",
    "            default_category = \"Unable to Classify\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac50cab-ee56-446b-89d1-0b240a89e5a5",
   "metadata": {},
   "source": [
    "## List-based label constraining of output\n",
    "\n",
    "- You can also constrain the output of a field to label names, by defining the list in the following format {Label Name}: {Label Description}\n",
    "    - Example input text: \"I am so elated!\"\n",
    "    - Example output format: {\"Sentiment\": [\"A: happy\", \"B: sad\", \"C: neutral\"]}\n",
    "    - Example output: {\"Sentiment\": \"A\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "117f9517-883b-412d-af33-ce0c314a35b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sentiment': 'A'}\n"
     ]
    }
   ],
   "source": [
    "res = strict_output(system_prompt = 'You are a friendly assistant meant to extract information from text', \n",
    "              user_prompt = \"I am so elated\",\n",
    "              output_format = {\"Sentiment\": [\"A: happy\", \"B: sad\", \"C: neutral\"]})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77689ea9-0443-4e84-aba7-f2d55fff3a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Summary': 'Once caught a fish alive, let go, bit finger', 'Entity Caught': 'living', 'Finger Bitten': 'A', 'Numbers': ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten']}\n"
     ]
    }
   ],
   "source": [
    "# If we are only interested in the label of the classification, we can specify the list as <Label Name>: <Label Description>\n",
    "# It would force the output into one label regardless whether it agrees or not with the categories\n",
    "res = strict_output(system_prompt = 'You are a friendly assistant meant to extract information from text', \n",
    "              user_prompt = text,\n",
    "              output_format = {\"Summary\": \"Summarize the text in 10 words\", \"Entity Caught\": [\"living\", \"non-living\"], \n",
    "                                 \"Finger Bitten\": [\"A: left\", \"B: middle\"], \"Numbers\": \"List of numbers\"})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d690daa0-af59-4bf7-9981-f2162695f81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Summary': 'Once caught a fish alive, let go, bit finger', 'Entity Caught': 'living', 'Finger Bitten': 'Unable to Classify', 'Numbers': ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten']}\n"
     ]
    }
   ],
   "source": [
    "# If we are only interested in the label of the classification, we can specify the list as <Label Name>: <Label Description>\n",
    "# If you want to GPT to flag out when a label is inaccurate, assign some text to default_category\n",
    "res = strict_output(system_prompt = 'You are a friendly assistant meant to extract information from text', \n",
    "              user_prompt = text,\n",
    "              output_format = {\"Summary\": \"Summarize the text in 10 words\", \"Entity Caught\": [\"living\", \"non-living\"], \n",
    "                                 \"Finger Bitten\": [\"A: left\", \"B: middle\"], \"Numbers\": \"List of numbers\"},\n",
    "              default_category = \"Unable to Classify\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a651e2-8add-4c8d-9831-0ed293a13040",
   "metadata": {},
   "source": [
    "# Dynamic output format\n",
    "- Used when we want to constrain the output in a largely fixed format but allow for some flexibility in some areas\n",
    "- Flexible areas are enclosed with <> alongside areas which are fixed\n",
    "    - Example: \"\\<entity\\> bit my \\<entity\\>\" means that we want GPT to replace the two <entity> tags, but preserve \"bit my\" exactly\n",
    "    - Example output: \"Fish bit my finger\"\n",
    "- <> can also be applied to the keys of json, but we will not be doing strict output checks on those fields since it will be dynamically generated\n",
    "- When <> is applied to the output key, GPT can generate the key name according to context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8195c6b9-34e4-48bf-a46a-540aec5e84af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Summary': 'Fish nibbled on my finger', 'Entity Caught': 'living', 'finger': 'injury was caused by fish'}\n"
     ]
    }
   ],
   "source": [
    "# If we are only interested in the label of the classification, we can specify the list as <Label Name>: <Label Description>\n",
    "# If you want to GPT to flag out when a label is inaccurate, assign some text to default_category\n",
    "res = strict_output(system_prompt = 'You are a friendly assistant meant to extract information from text', \n",
    "              user_prompt = text,\n",
    "              output_format = {\"Summary\": \"<entity> nibbled on my <entity>\", \"Entity Caught\": [\"living\", \"non-living\"], \n",
    "                                \"<location of injury>\": \"injury was caused by <entity>\"})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e21b036-ada6-4569-8d15-a611001be98d",
   "metadata": {},
   "source": [
    "## Chain-of-thought prompting via output format\n",
    "\n",
    "- You can also perform chain-of-thought prompting by ordering the json fields in the right way\n",
    "- Example\n",
    "    - Day planner has much better output if broad plan is generated first before detailed plan\n",
    "    - We can also prompt the model for thoughts, action, observation (ReAct framework) as part of json output\n",
    "    - We can also prompt the model for reflection (RefleXion framework), and even combine the two together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa329293-0eae-4461-a42b-65cfe099accd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Detailed Plan': ['9am - 11am: Badminton session', '11am - 12pm: Lunch', '12pm - 3pm: Webinar on LLMs', '3pm - 5pm: Board games session', '5pm - 6pm: Dinner', '6pm - 8pm: Netflix watching', '8pm - 10pm: Free time']}\n"
     ]
    }
   ],
   "source": [
    "res = strict_output(system_prompt = 'You are a day planner, meant to schedule the events of the day with some constraints. Output an hourly-based schedule.', \n",
    "              user_prompt = '''To-do-list:\n",
    "- 3 hour webinar on LLMs\n",
    "- 3 hour board games session\n",
    "- 1 hour for lunch and dinner\n",
    "- 2 hour Netflix watching\n",
    "- 2 hour badminton session\n",
    "\n",
    "Constraints:\n",
    "- Badminton session is the first thing of the day\n",
    "- Lunch between 11am to 1pm\n",
    "- Dinner between 6pm to 8pm\n",
    "- Awake only from 9am to 10pm''',\n",
    "              output_format = {\"Detailed Plan\": \"Hourly-based schedule in a list\"})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b12c30a-940d-4719-aa56-a9085fe82c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Broad Plan': 'Start the day with a 2 hour badminton session. Then, attend the 3 hour webinar on LLMs. Take a break for lunch from 11am to 1pm. After lunch, have a 3 hour board games session. Take another break for dinner from 6pm to 8pm. Finally, relax with 2 hours of Netflix watching before going to bed at 10pm.', 'Detailed Plan': ['9am - 11am: Badminton session', '11am - 1pm: Lunch', '1pm - 4pm: Webinar on LLMs', '4pm - 7pm: Board games session', '7pm - 8pm: Dinner', '8pm - 10pm: Netflix watching']}\n"
     ]
    }
   ],
   "source": [
    "res = strict_output(system_prompt = 'You are a day planner, meant to schedule the events of the day with some constraints. Output an hourly-based schedule.', \n",
    "              user_prompt = '''To-do-list:\n",
    "- 3 hour webinar on LLMs\n",
    "- 3 hour board games session\n",
    "- 1 hour for lunch and dinner\n",
    "- 2 hour Netflix watching\n",
    "- 2 hour badminton session\n",
    "\n",
    "Constraints:\n",
    "- Badminton session is the first thing of the day\n",
    "- Lunch between 11am to 1pm\n",
    "- Dinner between 6pm to 8pm\n",
    "- Awake only from 9am to 10pm''',\n",
    "              output_format = {\"Broad Plan\": \"Thoughts on how to achieve the desired schedule taking into account constraints\", \n",
    "                               \"Detailed Plan\": \"Hourly-based schedule in a list\"})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8f1af8d-cfa5-435b-9677-0a7b8f1bca51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Current State': 'Robot at Area A, John at Area B, can of coke at Area C', 'Thoughts': 'To give a can of coke to John, I need to pick up the can of coke from Area C and then move to Area B where John is located.', 'Action': 'move to Area C', 'Narration of robot performing one action': 'The robot moves to Area C to pick up the can of coke.', 'New State': 'Robot at Area C, John at Area B, can of coke at Robot', 'Reflection': 'The robot successfully picked up the can of coke from Area C.', 'Task completed': 'no'}\n",
      "{'Current State': 'Robot at Area C, John at Area B, can of coke at Robot', 'Thoughts': 'To give a can of coke to John, I need to move to Area B where John is located and then pass the can of coke to him.', 'Action': 'move to Area B', 'Narration of robot performing one action': 'The robot moves to Area B.', 'New State': 'Robot at Area B, John at Area B, can of coke at Robot', 'Reflection': 'Moving to the correct area is a good step towards completing the task. However, I still need to pass the can of coke to John.', 'Task completed': 'no'}\n",
      "{'Current State': 'Robot at Area B, John at Area B, can of coke at Robot', 'Thoughts': 'To give a can of coke to John, I need to be in the same area as John and have the can of coke in my possession.', 'Action': 'pass can of coke to John', 'Narration of robot performing one action': 'The robot passes the can of coke to John.', 'New State': 'Robot at Area B, John at Area B, can of coke at John', 'Reflection': 'The robot successfully passed the can of coke to John.', 'Task completed': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "# Robot Action Selector!\n",
    "# Usually the observation will be returned by the environment (or tool use), but here we will get GPT to just imagine it\n",
    "# we can just use the observation as the current state, and get the robot to continue generating the actions!\n",
    "res['New State'] = \"Robot at Area A, John at Area B, can of coke at Area C\"\n",
    "actions = []\n",
    "\n",
    "for i in range(4):\n",
    "    res = strict_output(system_prompt = '''You are a robot. User will give your your current state and your task. \n",
    "You are to choose an action to bring you closer to accomplishing the task.\n",
    "Constraints:\n",
    "- You pick up objects in the area automatically when you go into the area\n",
    "- You need to pass the object to another person explicitly within the same area''', \n",
    "                  user_prompt = f'''Current State: {res['New State']}, Past Actions: {actions}\n",
    "Task: Give a can of coke to John.''',\n",
    "                  output_format = {\"Current State\": \"describe the current state\",\n",
    "                                   \"Thoughts\": \"Thoughts on how to achieve the task from current state\", \n",
    "                                   \"Action\": [\"move to <area>: move to <area>\", \n",
    "                                              \"pass <object> to <person>: usable only when robot has <object> and is at same location as <person>\",\n",
    "                                              \"end: when nothing else is needed\"], \n",
    "                                   \"Narration of robot performing one action\": \"describe what the robot did from current state\",\n",
    "                                   \"New State\": \"generate the locations of robot, person and coke are at after performing action from current state\",\n",
    "                                   \"Reflection\": \"reflect on what has been done well, what has been done wrong\",\n",
    "                                   \"Task completed\": [\"yes\", \"no\"]})\n",
    "    print(res)\n",
    "    \n",
    "    actions.append(res['Action'])\n",
    "    # Exit if task is completed\n",
    "    if res['Task completed'] == 'yes': break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd034912-9169-4c3d-9ae6-ddc23e191b27",
   "metadata": {},
   "source": [
    "# Handling Input as a List\n",
    "- In order to save tokens, we may want to process multiple input items using the same output_format schema\n",
    "- We can then pass in a list into user_prompt to get the function to output a list of json\n",
    "- There will be one json in the output for each element of the input list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91ca3d71-bb41-41dc-8055-e494217d9cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Sentiment': 'happy'}, {'Sentiment': 'sad'}, {'Sentiment': 'boring'}]\n"
     ]
    }
   ],
   "source": [
    "## We can get a list of json for each element in user_prompt\n",
    "out = strict_output(system_prompt = \"You are to classify the user sentiments.\",\n",
    "                   user_prompt = [\"This is such a beautiful day\", \"My heart is aching\", \"Time is passing by so slowly\"],\n",
    "                   output_format = {\"Sentiment\": [\"sad\", \"boring\", \"happy\", \"unknown\"]})\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fc6d0d2-7465-4f92-a3c5-91a1c6463e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Sentiment': 'C', 'beautiful day': 'a day that is pleasing to the senses'}, {'Sentiment': 'A', 'heart': 'the organ in the body that pumps blood'}, {'Sentiment': 'B', 'time': 'the indefinite continued progress of existence and events in the past, present, and future regarded as a whole'}]\n"
     ]
    }
   ],
   "source": [
    "## We can get a list of json for each element in user_prompt\n",
    "## Each json can contain multiple elements\n",
    "out = strict_output(system_prompt = \"You are to classify the user sentiments.\",\n",
    "                   user_prompt = [\"This is such a beautiful day\", \"My heart is aching\", \"Time is passing by so slowly\"],\n",
    "                   output_format = {\"Sentiment\": [\"A: sad\", \"B: boring\", \"C: happy\", \"D: unknown\"],\n",
    "                                   \"<main entity>\": \"Definition of entity\"})\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7cd7c57-80cb-422f-92c0-12dc20620be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'A', 'B']\n"
     ]
    }
   ],
   "source": [
    "## Ensures that output works for multiple item list format\n",
    "## We can get list of values by setting output_values_only to be true\n",
    "## Note: This is just post-processing, output of GPT will still be a json\n",
    "out = strict_output(system_prompt = \"You are to classify the user sentiments.\",\n",
    "                   user_prompt = [\"This is such a beautiful day\", \"My heart is aching\", \"Time is passing by so slowly\"],\n",
    "                   output_format = {\"Sentiment\": [\"A: sad\", \"B: boring\", \"C: happy\", \"D: unknown\"]},\n",
    "                   output_value_only = True)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96cc661-2cbe-4d90-bd8b-5a5e56eee5af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
