{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a3bd0fb-7d87-4992-beb0-f622d61c467c",
   "metadata": {},
   "source": [
    "# Context-Dependent Embeddings\n",
    "\n",
    "- Modified 13 Feb 2024\n",
    "\n",
    "- This is the notebook for the experiments of the Embeddings walkthrough session\n",
    "- https://www.youtube.com/watch?v=gVZryxJRdSY\n",
    "\n",
    "- Key findings:\n",
    "    - Long chunks of similar text tends to make the model classify embeddings as more similar (Key Finding 1)\n",
    "    - Prepending Context (Approach 1) and appending context (Approach 1.5) do not solve this problem\n",
    "    - Modifying text based on context (Approach 2) appears to solve this problem\n",
    "    \n",
    "- Other findings:\n",
    "    - text-embedding-3-large and text-embedding-3-small handles negation well compared to text-embedding-ada-002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e2fe290-b624-48ad-9af7-0e3c141be3e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "#API Keys\n",
    "os.environ['OPENAI_API_KEY'] = '<YOUR OPENAI KEY HERE>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ba758f-9e53-44fe-90cc-3281089fe6d0",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8710e422-e7cb-45a5-a080-382b551b62ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chat(system_prompt: str, user_prompt: str, model: str = 'gpt-3.5-turbo', temperature: float = 0, verbose: bool = False, host: str = 'openai', **kwargs):\n",
    "    '''Performs a chat with the host's LLM model with system prompt, user prompt, model, verbose and kwargs\n",
    "    Returns the output string res\n",
    "    - system_prompt: String. Write in whatever you want the LLM to become. e.g. \"You are a \\<purpose in life\\>\"\n",
    "    - user_prompt: String. The user input. Later, when we use it as a function, this is the function input\n",
    "    - model: String. The LLM model to use for json generation\n",
    "    - verbose: Boolean (default: False). Whether or not to print out the system prompt, user prompt, GPT response\n",
    "    - host: String. The provider of the LLM\n",
    "    - **kwargs: Dict. Additional arguments for LLM chat'''\n",
    "    \n",
    "    if host == 'openai':\n",
    "        client = OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            temperature = temperature,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            **kwargs\n",
    "        )\n",
    "        res = response.choices[0].message.content\n",
    "\n",
    "        if verbose:\n",
    "            print('System prompt:', system_prompt)\n",
    "            print('\\nUser prompt:', user_prompt)\n",
    "            print('\\nGPT response:', res)\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04c7ea79-8cf7-4aa0-9d55-78a302322239",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_embedding(text: str, model=\"text-embedding-3-large\", num_tries = 10):\n",
    "    ''' Generates a text embedding using OpenAI Embeddings \n",
    "    Gives num_tries repeat before moving on to cater for API throttling issues'''\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    for tries in range(num_tries):\n",
    "        try:\n",
    "            client = OpenAI()\n",
    "            embedding = client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "            break    \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ea0f8f8b-cab5-4bf0-b4bd-c9291e19bc46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def top_k_neighbours(query_embedding: list, embedding_list: list, k:int = 3, removedindex: list = []):\n",
    "    ''' Given a query embedding, finds out the top k embeddings that are the most relevant\n",
    "    Returns the index vector of top k embeddings, in sorted order from most relevant to least relevant'''\n",
    "    embedding_similarity = [np.dot(query_embedding, emb) for emb in embedding_list]\n",
    "    # set some indices to 0\n",
    "    np.array(embedding_similarity)[selectedindex] = 0\n",
    "    # this is if you do not care about the order in the top k\n",
    "    # return np.argpartition(embedding_similarity, -k)[-k:] \n",
    "    # this is if you care about order in the top k\n",
    "    return np.argsort(embedding_similarity)[-k:][::-1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aa4b5e-a42f-4234-8984-d30b926598d8",
   "metadata": {},
   "source": [
    "# Key Finding 1: Shorter text is better for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "76cab136-8ba6-4e00-8596-17de65530849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'text-embedding-3-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3d662559-151c-482b-9f49-ccf494a31c09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9297407654620802"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"John went to the supermarket. Peter went to the gym. Mary went to the garden.\"\n",
    "text2 = \"John went to the airport. Peter went to the gym. Mary went to the garden.\"\n",
    "np.dot(get_embedding(text1, model), get_embedding(text2, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "233cead4-56f9-471c-8e23-fd458cd7f455",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9600638691627703"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"Peter went to the gym. Mary went to the garden. John went to the supermarket.\"\n",
    "text2 = \"Peter went to the gym. Mary went to the garden. John went to the airport.\"\n",
    "np.dot(get_embedding(text1, model), get_embedding(text2, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "758b2a14-ce9a-4d9a-870f-d046340505d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6328660633894473"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"John went to the supermarket.\"\n",
    "text2 = \"John went to the airport.\"\n",
    "np.dot(get_embedding(text1, model), get_embedding(text2, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cee2d3-9ca2-4e29-bdf6-ed4240fe472d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Context Dependent Embeddings (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0eaaa804-4a1c-43e5-9f1f-58061ced880d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'text-embedding-3-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fb7ad3a7-af76-4f45-a950-98704b0c686d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5897400164080131"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be similar\n",
    "np.dot(get_embedding('I went to the bank', model), get_embedding('I went to the river', model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fd93253e-83d6-4f4e-8dfc-fa41247f4fa7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8018812180559"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be similar\n",
    "np.dot(get_embedding('I went to the bank', model), get_embedding('I went to get money', model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1676da5-c798-4e93-a0ba-6edc33962542",
   "metadata": {},
   "source": [
    "# Context Dependent Embeddings (Approach 1) - Prepending context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "915508be-5b65-489b-9091-aff4544c2af7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7513987620212337"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be similar\n",
    "np.dot(get_embedding('Context: water. I went to the bank', model), \n",
    "       get_embedding('Context: water. I went to the river', model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3935a913-b998-4e20-aa9c-9d973f22ecf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8789128046393934"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be different\n",
    "np.dot(get_embedding('Context: water. I went to the bank', model), \n",
    "       get_embedding('Context: water. I went to get money', model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3a465835-5d71-433d-8825-41c01209a251",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7817484942487075"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be different\n",
    "np.dot(get_embedding('Context: finance. I went to the bank', model), \n",
    "       get_embedding('Context: finance. I went to the river', model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1ea2ba24-0619-46f8-8e20-3a49254942c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8711684911398004"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be similar\n",
    "np.dot(get_embedding('Context: finance. I went to the bank', model), \n",
    "       get_embedding('Context: finance. I went to get money', model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a023ee-1888-4563-9aeb-45964b35ae4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Context Dependent Embeddings (Approach 1.5) - Appending context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc480678-65d6-4871-b03e-8b52acdb33a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8096693719142252"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be similar\n",
    "np.dot(get_embedding('I went to the bank. Summarise this sentence in context of water:', model), \n",
    "       get_embedding('I went to the river. Summarise this sentence in context of water:', model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "87ed1758-dbbb-4516-acf3-83c526f4918c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9065902572233908"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be different\n",
    "np.dot(get_embedding('I went to the bank. Summarise this sentence in context of water:', model), \n",
    "       get_embedding('I went to get money. Summarise this sentence in context of water:', model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "52092f3b-7374-4f41-8097-b57fbc21e0dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8251738788226315"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be different\n",
    "np.dot(get_embedding('I went to the bank. Summarise this sentence in context of finance:', model), \n",
    "       get_embedding('I went to the river. Summarise this sentence in context of finance:', model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9b3e2909-b173-42a2-93f6-6d8e800f1d5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9151529270746628"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be similar\n",
    "np.dot(get_embedding('I went to the bank. Summarise this sentence in context of finance:', model), \n",
    "       get_embedding('I went to get money. Summarise this sentence in context of finance:', model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079470a0-acd3-400a-9c61-1a8baf73b610",
   "metadata": {},
   "source": [
    "# Context Dependent Embeddings (Approach 2) - Modify the text prompt and use it for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ca94be16-1633-42f3-8475-5d1228802ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_conversion(context, text):\n",
    "    return chat(f'''Context is {context}. \n",
    "Refine text based on context without changing the text's meaning.\n",
    "Do not add in what is not present in the text.\n",
    "Some parts of the text may have more meaning based on context, highlight those.\n",
    "If unable to refine, output original text''', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a3e33b5c-1afc-481f-bae1-8e32e10fdec4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I read an academic paper.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_conversion('academia', 'I read a paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "54f2fb55-389c-4344-827d-14d26a184a3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I read a news article.'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_conversion('news', 'I read a paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "70a95c7d-c318-412e-8a9c-2d8ebd2933a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I read an exam paper.'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_conversion('exam', 'I read a paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "37f17368-8970-4c41-ab6e-8e541b2be88d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'text-embedding-3-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "67b3adf2-5050-4e04-a14b-70891e834447",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_embedding_by_context(text: str, context: str = '', model: str = 'gpt-3.5-turbo'):\n",
    "    ''' Gets an embedding based on the context. If context not given, does not do conversion '''\n",
    "    converted_sentence = text_conversion(context, text) if context != '' else text\n",
    "    return get_embedding(converted_sentence, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "060f3fa3-c297-4b13-bf6f-aeff14061191",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding similarity 0.5897400164080131\n"
     ]
    }
   ],
   "source": [
    "# should be similar\n",
    "x, y, context = 'I went to the bank', 'I went to the river', ''\n",
    "print('Embedding similarity', np.dot(get_embedding_by_context(x, context, model), \n",
    "                                     get_embedding_by_context(y, context, model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6a6129cd-50c8-46bb-87b9-bb424b90dfdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding similarity 0.8759913799435554\n"
     ]
    }
   ],
   "source": [
    "# should be similar\n",
    "x, y, context = 'I went to the bank', 'I went to the river', 'water'\n",
    "print('Embedding similarity', np.dot(get_embedding_by_context(x, context, model), \n",
    "                                     get_embedding_by_context(y, context, model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "59b2b9bc-5a6b-4c5a-ae6f-7fab41cb21f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding similarity 0.4956905762475252\n"
     ]
    }
   ],
   "source": [
    "# should be different\n",
    "x, y, context = 'I went to the bank', 'I went to the river', 'finance'\n",
    "print('Embedding similarity', np.dot(get_embedding_by_context(x, context, model), \n",
    "                                     get_embedding_by_context(y, context, model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d8841b20-9f3f-4585-9bec-17a6da890977",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding similarity 0.8018812180559\n"
     ]
    }
   ],
   "source": [
    "# should be similar\n",
    "x, y, context = 'I went to the bank', 'I went to get money', ''\n",
    "print('Embedding similarity', np.dot(get_embedding_by_context(x, context, model), \n",
    "                                     get_embedding_by_context(y, context, model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a59c84cc-37db-443d-a763-63e0648f37ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding similarity 0.5029410724258297\n"
     ]
    }
   ],
   "source": [
    "# should be different\n",
    "x, y, context = 'I went to the bank', 'I went to get money', 'water'\n",
    "print('Embedding similarity', np.dot(get_embedding_by_context(x, context, model), \n",
    "                                     get_embedding_by_context(y, context, model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b9714561-6138-47b8-9a7d-c956f5de6e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding similarity 0.6847778551131576\n"
     ]
    }
   ],
   "source": [
    "# should be similar\n",
    "x, y, context = 'I went to the bank', 'I went to get money', 'finance'\n",
    "print('Embedding similarity', np.dot(get_embedding_by_context(x, context, model), \n",
    "                                     get_embedding_by_context(y, context, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6302a147-5801-4bc5-bd55-1273ff1029af",
   "metadata": {},
   "source": [
    "# Negation of values (text-embedding-3-large)\n",
    "- More performant compared to text-embedding-ada-002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e222a558-9d39-4e68-91e2-dd80ac587e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'text-embedding-3-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "37e985e2-776f-4260-8430-b16788d6d6b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.537687984526523"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(get_embedding('have', model), get_embedding('do not have', model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f1d459a6-2af2-4161-98e9-38d3a0e5c938",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7664456530397772"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(get_embedding('Jonathan was present', model), get_embedding('Jonathan was absent', model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "38b571c0-f4f5-4720-bc54-a438d5fc5ef6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38758236896648085"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(get_embedding('present', model), get_embedding('absent', model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0e7d6476-1b20-4df9-819f-a92c0fde2a5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48815064811640596"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(get_embedding('present', model), get_embedding('not present', model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbc5e22-0e5b-405c-b1c1-7417071cbf2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Negation of values (text-embedding-ada-002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4f51e445-cca5-41d2-9f10-691058661bed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'text-embedding-ada-002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b0a33285-e39b-4f6a-aa0b-7eccb7958ceb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8612163753882298"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(get_embedding('have', model), get_embedding('do not have', model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "90b0c68e-0b3c-4991-b5ac-d306142658dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9487405481131359"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(get_embedding('Jonathan was present', model), get_embedding('Jonathan was absent', model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "abdfc4c9-1ce6-4f4a-991f-1d2f95995acd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8294703415200366"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(get_embedding('present', model), get_embedding('absent', model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3c90f471-e2b9-4e4e-a652-a234f6ef0780",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8508408212164676"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(get_embedding('present', model), get_embedding('not present', model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a4146-bad6-43c2-bc57-f0e6cc0745e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Negation of values (text-embedding-3-small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bda1a5dc-9985-4a24-aff0-39968794b474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'text-embedding-3-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cffe7e84-4509-4f59-86a5-8a46ca523b91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5316601210294082"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(get_embedding('have', model), get_embedding('do not have', model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "881a5d63-34c3-4388-8dfd-4651b58de693",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.835158308129629"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(get_embedding('Jonathan was present', model), get_embedding('Jonathan was absent', model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6e220cfd-f4bd-4140-8d54-ec1f3805313b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4002265066603564"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(get_embedding('present', model), get_embedding('absent', model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4feeb813-f258-4c53-8ec1-99fd024717be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44254542744698094"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(get_embedding('present', model), get_embedding('not present', model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
